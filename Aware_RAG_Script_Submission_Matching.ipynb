{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TDPInX7gEvwS",
    "outputId": "1367d8eb-b80f-45dd-d2f0-9354556d0f16"
   },
   "outputs": [],
   "source": [
    "#installation and import statements\n",
    "\n",
    "# ! pip install lancedb\n",
    "# ! pip install sentence_transformers\n",
    "# ! pip install llama-cpp-python\n",
    "\n",
    "from __future__ import annotations\n",
    "import numpy as np\n",
    "import time\n",
    "import lancedb # our vector database\n",
    "from lancedb.embeddings import get_registry #embedding registry\n",
    "from lancedb.pydantic import LanceModel, Vector, pydantic_to_schema\n",
    "from lancedb.embeddings import TextEmbeddingFunction\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "from tqdm.auto import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "import transformers\n",
    "import torch\n",
    "from llama_cpp import Llama\n",
    "import json\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kLr24ebMKKa6"
   },
   "source": [
    "## Get Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "psEZ7AR7EyQH",
    "outputId": "b391c02f-3c0f-4ff5-aed0-123903c62d00"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aware_post_type</th>\n",
       "      <th>aware_created_ts</th>\n",
       "      <th>reddit_id</th>\n",
       "      <th>reddit_name</th>\n",
       "      <th>reddit_created_utc</th>\n",
       "      <th>reddit_author</th>\n",
       "      <th>reddit_text</th>\n",
       "      <th>reddit_permalink</th>\n",
       "      <th>reddit_title</th>\n",
       "      <th>reddit_url</th>\n",
       "      <th>reddit_subreddit</th>\n",
       "      <th>reddit_link_id</th>\n",
       "      <th>reddit_parent_id</th>\n",
       "      <th>reddit_submission</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>submission</td>\n",
       "      <td>2023-04-02T13:58:03</td>\n",
       "      <td>129sqka</td>\n",
       "      <td>t3_129sqka</td>\n",
       "      <td>1680458283</td>\n",
       "      <td>MoodyStarGirl</td>\n",
       "      <td>That's it.</td>\n",
       "      <td>/r/starbucks/comments/129sqka/hot_chai_lattes_...</td>\n",
       "      <td>Hot chai lattes shouldn't have water</td>\n",
       "      <td>https://www.reddit.com/r/starbucks/comments/12...</td>\n",
       "      <td>starbucks</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>comment</td>\n",
       "      <td>2023-04-02T14:32:57</td>\n",
       "      <td>jeounwc</td>\n",
       "      <td>t1_jeounwc</td>\n",
       "      <td>1680460377</td>\n",
       "      <td>Lost_Treat_6296</td>\n",
       "      <td>We should make the chai tea latte with the sam...</td>\n",
       "      <td>/r/starbucks/comments/129sqka/hot_chai_lattes_...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>starbucks</td>\n",
       "      <td>t3_129sqka</td>\n",
       "      <td>t3_129sqka</td>\n",
       "      <td>129sqka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>comment</td>\n",
       "      <td>2023-04-02T14:48:18</td>\n",
       "      <td>jeowus2</td>\n",
       "      <td>t1_jeowus2</td>\n",
       "      <td>1680461298</td>\n",
       "      <td>MoodyStarGirl</td>\n",
       "      <td>Oh like using the chai tea bags?</td>\n",
       "      <td>/r/starbucks/comments/129sqka/hot_chai_lattes_...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>starbucks</td>\n",
       "      <td>t3_129sqka</td>\n",
       "      <td>t1_jeounwc</td>\n",
       "      <td>129sqka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>comment</td>\n",
       "      <td>2023-04-02T14:48:49</td>\n",
       "      <td>jeowxe5</td>\n",
       "      <td>t1_jeowxe5</td>\n",
       "      <td>1680461329</td>\n",
       "      <td>Lost_Treat_6296</td>\n",
       "      <td>No, the whole half water and half milk thing</td>\n",
       "      <td>/r/starbucks/comments/129sqka/hot_chai_lattes_...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>starbucks</td>\n",
       "      <td>t3_129sqka</td>\n",
       "      <td>t1_jeowus2</td>\n",
       "      <td>129sqka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>comment</td>\n",
       "      <td>2023-04-02T21:59:22</td>\n",
       "      <td>jeqiuw3</td>\n",
       "      <td>t1_jeqiuw3</td>\n",
       "      <td>1680487162</td>\n",
       "      <td>MoodyStarGirl</td>\n",
       "      <td>That's a lot of water :(</td>\n",
       "      <td>/r/starbucks/comments/129sqka/hot_chai_lattes_...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>starbucks</td>\n",
       "      <td>t3_129sqka</td>\n",
       "      <td>t1_jeowxe5</td>\n",
       "      <td>129sqka</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  aware_post_type     aware_created_ts reddit_id reddit_name  \\\n",
       "0      submission  2023-04-02T13:58:03   129sqka  t3_129sqka   \n",
       "1         comment  2023-04-02T14:32:57   jeounwc  t1_jeounwc   \n",
       "2         comment  2023-04-02T14:48:18   jeowus2  t1_jeowus2   \n",
       "3         comment  2023-04-02T14:48:49   jeowxe5  t1_jeowxe5   \n",
       "4         comment  2023-04-02T21:59:22   jeqiuw3  t1_jeqiuw3   \n",
       "\n",
       "   reddit_created_utc    reddit_author  \\\n",
       "0          1680458283    MoodyStarGirl   \n",
       "1          1680460377  Lost_Treat_6296   \n",
       "2          1680461298    MoodyStarGirl   \n",
       "3          1680461329  Lost_Treat_6296   \n",
       "4          1680487162    MoodyStarGirl   \n",
       "\n",
       "                                         reddit_text  \\\n",
       "0                                         That's it.   \n",
       "1  We should make the chai tea latte with the sam...   \n",
       "2                   Oh like using the chai tea bags?   \n",
       "3       No, the whole half water and half milk thing   \n",
       "4                           That's a lot of water :(   \n",
       "\n",
       "                                    reddit_permalink  \\\n",
       "0  /r/starbucks/comments/129sqka/hot_chai_lattes_...   \n",
       "1  /r/starbucks/comments/129sqka/hot_chai_lattes_...   \n",
       "2  /r/starbucks/comments/129sqka/hot_chai_lattes_...   \n",
       "3  /r/starbucks/comments/129sqka/hot_chai_lattes_...   \n",
       "4  /r/starbucks/comments/129sqka/hot_chai_lattes_...   \n",
       "\n",
       "                           reddit_title  \\\n",
       "0  Hot chai lattes shouldn't have water   \n",
       "1                                  None   \n",
       "2                                  None   \n",
       "3                                  None   \n",
       "4                                  None   \n",
       "\n",
       "                                          reddit_url reddit_subreddit  \\\n",
       "0  https://www.reddit.com/r/starbucks/comments/12...        starbucks   \n",
       "1                                               None        starbucks   \n",
       "2                                               None        starbucks   \n",
       "3                                               None        starbucks   \n",
       "4                                               None        starbucks   \n",
       "\n",
       "  reddit_link_id reddit_parent_id reddit_submission  \n",
       "0           None             None              None  \n",
       "1     t3_129sqka       t3_129sqka           129sqka  \n",
       "2     t3_129sqka       t1_jeounwc           129sqka  \n",
       "3     t3_129sqka       t1_jeowus2           129sqka  \n",
       "4     t3_129sqka       t1_jeowxe5           129sqka  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_json = pd.read_json(\"../AwareData/reddit.json\")\n",
    "data=pd.DataFrame(data_json)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess\n",
    "\n",
    "Add a column of reddit subreddit labels \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddits = data['reddit_subreddit'].unique()\n",
    "label_dict = dict(zip(subreddits, range(len(subreddits))))\n",
    "\n",
    "# label_dict = {'starbucks': 0,\n",
    "#             'starbucksbaristas': 1,\n",
    "#             'UPSers': 2,\n",
    "#             'Lowes': 3,\n",
    "#             'DollarTree': 4,\n",
    "#             'WalmartEmployees': 5,\n",
    "#             'McLounge': 6,\n",
    "#             'Fedexers': 7,\n",
    "#             'TjMaxx': 8,\n",
    "#             'RiteAid': 9,\n",
    "#             'walmart': 10,\n",
    "#             'TalesFromYourBank': 11,\n",
    "#             'KrakenSupport': 12,\n",
    "#             'BestBuyWorkers': 13,\n",
    "#             'Bestbuy': 14,\n",
    "#             'CVS': 15,\n",
    "#             'Target': 16,\n",
    "#             'disney': 17,\n",
    "#             'Disneyland': 17,\n",
    "#             'DisneyWorld': 17,\n",
    "#             'WaltDisneyWorld': 17}\n",
    "\n",
    "data['reddit_subreddit_label'] = data['reddit_subreddit'].apply(lambda x: label_dict[x])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Add a column of indices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:, 'index'] = data.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove all line breaks in reddit_text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(data)):\n",
    "#      data.loc[i, 'reddit_text'] = data.loc[i, 'reddit_text'].replace('\\n', ' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('data/reddit.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Make a new dataframe of submissions only.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = data.loc[data['aware_post_type']=='submission'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Combine submission title and text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs.loc[:, 'text_and_title'] = [str(subs['reddit_title'].iloc[i]) + ' ' + str(subs['reddit_text'].iloc[i]) + '#' + str(subs['reddit_subreddit'].iloc[i]) for i in range(len(subs))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Add a column of comment indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs['comment_indices'] = [[] for _ in range(len(subs))]\n",
    "for i in range(len(subs)):\n",
    "    sub_index = subs.loc[i, 'index']\n",
    "    next_sub_index = len(data) if i == len(subs)-1 else subs.loc[i+1,'index']\n",
    "    for j in range(sub_index+1, next_sub_index):\n",
    "        if data.loc[j, 'reddit_parent_id'] == subs.loc[i, 'reddit_name']:\n",
    "            subs['comment_indices'].iloc[i].append(data.loc[j,'index'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Drop submissons with no comments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = subs.drop(subs[subs['comment_indices'].str.len()==0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aware_post_type</th>\n",
       "      <th>aware_created_ts</th>\n",
       "      <th>reddit_id</th>\n",
       "      <th>reddit_name</th>\n",
       "      <th>reddit_created_utc</th>\n",
       "      <th>reddit_author</th>\n",
       "      <th>reddit_text</th>\n",
       "      <th>reddit_permalink</th>\n",
       "      <th>reddit_title</th>\n",
       "      <th>reddit_url</th>\n",
       "      <th>reddit_subreddit</th>\n",
       "      <th>reddit_link_id</th>\n",
       "      <th>reddit_parent_id</th>\n",
       "      <th>reddit_submission</th>\n",
       "      <th>reddit_subreddit_label</th>\n",
       "      <th>index</th>\n",
       "      <th>text_and_title</th>\n",
       "      <th>comment_indices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>submission</td>\n",
       "      <td>2023-04-02T13:58:03</td>\n",
       "      <td>129sqka</td>\n",
       "      <td>t3_129sqka</td>\n",
       "      <td>1680458283</td>\n",
       "      <td>MoodyStarGirl</td>\n",
       "      <td>That's it.</td>\n",
       "      <td>/r/starbucks/comments/129sqka/hot_chai_lattes_...</td>\n",
       "      <td>Hot chai lattes shouldn't have water</td>\n",
       "      <td>https://www.reddit.com/r/starbucks/comments/12...</td>\n",
       "      <td>starbucks</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hot chai lattes shouldn't have water That's it...</td>\n",
       "      <td>[1, 5, 12, 13]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>submission</td>\n",
       "      <td>2023-04-02T14:07:43</td>\n",
       "      <td>129t0vd</td>\n",
       "      <td>t3_129t0vd</td>\n",
       "      <td>1680458863</td>\n",
       "      <td>kotakehoe</td>\n",
       "      <td>i had the urge to make a cute baby frapp in a ...</td>\n",
       "      <td>/r/starbucks/comments/129t0vd/my_cute_little_f...</td>\n",
       "      <td>my cute little frappucino :)</td>\n",
       "      <td>https://i.redd.it/0gd8tk2zyjra1.jpg</td>\n",
       "      <td>starbucks</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>my cute little frappucino :) i had the urge to...</td>\n",
       "      <td>[19, 20]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>submission</td>\n",
       "      <td>2023-04-02T14:20:39</td>\n",
       "      <td>129te77</td>\n",
       "      <td>t3_129te77</td>\n",
       "      <td>1680459639</td>\n",
       "      <td>Extension_Cricket_30</td>\n",
       "      <td>Hey guys! I was wondering what benefits people...</td>\n",
       "      <td>/r/starbucks/comments/129te77/partner_benefits...</td>\n",
       "      <td>Partner Benefits at your Starbucks?</td>\n",
       "      <td>https://www.reddit.com/r/starbucks/comments/12...</td>\n",
       "      <td>starbucks</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>Partner Benefits at your Starbucks? Hey guys! ...</td>\n",
       "      <td>[27, 28, 29]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>submission</td>\n",
       "      <td>2023-04-02T14:39:11</td>\n",
       "      <td>129txfg</td>\n",
       "      <td>t3_129txfg</td>\n",
       "      <td>1680460751</td>\n",
       "      <td>ateez-lvr</td>\n",
       "      <td>did anyone notice (or is it the same for you a...</td>\n",
       "      <td>/r/starbucks/comments/129txfg/not_really_a_ran...</td>\n",
       "      <td>not really a rant, just an observation</td>\n",
       "      <td>https://www.reddit.com/r/starbucks/comments/12...</td>\n",
       "      <td>starbucks</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>not really a rant, just an observation did any...</td>\n",
       "      <td>[31, 37]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>submission</td>\n",
       "      <td>2023-04-02T14:43:36</td>\n",
       "      <td>129u231</td>\n",
       "      <td>t3_129u231</td>\n",
       "      <td>1680461016</td>\n",
       "      <td>chuchae</td>\n",
       "      <td>hi friends,   so i recently got back from a we...</td>\n",
       "      <td>/r/starbucks/comments/129u231/accidental_no_show/</td>\n",
       "      <td>accidental no show</td>\n",
       "      <td>https://www.reddit.com/r/starbucks/comments/12...</td>\n",
       "      <td>starbucks</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>accidental no show hi friends,   so i recently...</td>\n",
       "      <td>[39]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  aware_post_type     aware_created_ts reddit_id reddit_name  \\\n",
       "0      submission  2023-04-02T13:58:03   129sqka  t3_129sqka   \n",
       "1      submission  2023-04-02T14:07:43   129t0vd  t3_129t0vd   \n",
       "2      submission  2023-04-02T14:20:39   129te77  t3_129te77   \n",
       "3      submission  2023-04-02T14:39:11   129txfg  t3_129txfg   \n",
       "4      submission  2023-04-02T14:43:36   129u231  t3_129u231   \n",
       "\n",
       "   reddit_created_utc         reddit_author  \\\n",
       "0          1680458283         MoodyStarGirl   \n",
       "1          1680458863             kotakehoe   \n",
       "2          1680459639  Extension_Cricket_30   \n",
       "3          1680460751             ateez-lvr   \n",
       "4          1680461016               chuchae   \n",
       "\n",
       "                                         reddit_text  \\\n",
       "0                                         That's it.   \n",
       "1  i had the urge to make a cute baby frapp in a ...   \n",
       "2  Hey guys! I was wondering what benefits people...   \n",
       "3  did anyone notice (or is it the same for you a...   \n",
       "4  hi friends,   so i recently got back from a we...   \n",
       "\n",
       "                                    reddit_permalink  \\\n",
       "0  /r/starbucks/comments/129sqka/hot_chai_lattes_...   \n",
       "1  /r/starbucks/comments/129t0vd/my_cute_little_f...   \n",
       "2  /r/starbucks/comments/129te77/partner_benefits...   \n",
       "3  /r/starbucks/comments/129txfg/not_really_a_ran...   \n",
       "4  /r/starbucks/comments/129u231/accidental_no_show/   \n",
       "\n",
       "                             reddit_title  \\\n",
       "0    Hot chai lattes shouldn't have water   \n",
       "1            my cute little frappucino :)   \n",
       "2     Partner Benefits at your Starbucks?   \n",
       "3  not really a rant, just an observation   \n",
       "4                      accidental no show   \n",
       "\n",
       "                                          reddit_url reddit_subreddit  \\\n",
       "0  https://www.reddit.com/r/starbucks/comments/12...        starbucks   \n",
       "1                https://i.redd.it/0gd8tk2zyjra1.jpg        starbucks   \n",
       "2  https://www.reddit.com/r/starbucks/comments/12...        starbucks   \n",
       "3  https://www.reddit.com/r/starbucks/comments/12...        starbucks   \n",
       "4  https://www.reddit.com/r/starbucks/comments/12...        starbucks   \n",
       "\n",
       "  reddit_link_id reddit_parent_id reddit_submission  reddit_subreddit_label  \\\n",
       "0           None             None              None                       0   \n",
       "1           None             None              None                       0   \n",
       "2           None             None              None                       0   \n",
       "3           None             None              None                       0   \n",
       "4           None             None              None                       0   \n",
       "\n",
       "   index                                     text_and_title comment_indices  \n",
       "0      0  Hot chai lattes shouldn't have water That's it...  [1, 5, 12, 13]  \n",
       "1     18  my cute little frappucino :) i had the urge to...        [19, 20]  \n",
       "2     26  Partner Benefits at your Starbucks? Hey guys! ...    [27, 28, 29]  \n",
       "3     30  not really a rant, just an observation did any...        [31, 37]  \n",
       "4     38  accidental no show hi friends,   so i recently...            [39]  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subs[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZ_umitVNHCQ"
   },
   "source": [
    "# Embedding\n",
    "\n",
    "Define the embedding function\n",
    "\n",
    "Generate the vector embeddings for each submission text and title and store them in the vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\", device)\n",
    "\n",
    "vectors = model.encode(subs['text_and_title'].values.tolist(),\n",
    "                       convert_to_numpy=True,\n",
    "                       normalize_embeddings=True)\n",
    "\n",
    "subs['vector'] = vectors.tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open LanceDB and store embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "db = lancedb.connect(\"~/.lancedb\")\n",
    "table = db.create_table('reddit', subs, mode='overwrite')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build RAG pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We search through submission database and pull out comment information from full database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:  What is chai made of?\n",
      "\n",
      "Submission title:  Chai latte\n",
      "Submission text: Newbie here. How is a hot Chai latte made? Thanks!\n",
      "Comment:\n",
      " 1. Steam 2% milk 2. Pump chai: 2/3/4/5 for short/tall/grande/venti  3. Fill cup halfway with hot water 4. Fill remaining half with steamed milk  (https://sbuxdates.com is a great site for checking recipes)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Query\n",
    "query_string = \"What is chai made of?\" \n",
    "print(\"Query: \",query_string)\n",
    "print()\n",
    "query = model.encode(query_string,\n",
    "                       convert_to_numpy=True,\n",
    "                       normalize_embeddings=True).tolist()\n",
    "\n",
    "#retrieval\n",
    "response = table.search(query).limit(1).to_pandas()\n",
    "response\n",
    "\n",
    "response_str=\"\"\n",
    "#build context (submission + top comment for each retrieved post)\n",
    "for i in range(len(response)):\n",
    "    sub_index = response.loc[i, 'index']\n",
    "    comment_indices = response.loc[i, 'comment_indices']\n",
    "    print('Submission title: ', data.loc[sub_index, 'reddit_title'])\n",
    "    print('Submission text:', data.loc[sub_index, 'reddit_text'])\n",
    "    print('Comment:\\n', data.loc[comment_indices[0], 'reddit_text'])\n",
    "    \n",
    "    response_str = response_str + ' Submission title: ' +  data.loc[sub_index, 'reddit_title'] + ' Submission text: ' + data.loc[sub_index, 'reddit_text'] + ' Comment: ' + data.loc[comment_indices[0], 'reddit_text']\n",
    "    print()\n",
    "    \n",
    "# print(response_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize LLM\n",
    "\n",
    "I'm using the smallish llama 2 with 7 billion parameters.\n",
    "\n",
    "This little llama seems okayish at convesation, but a few weeks ago it told me that comets were made of 90% ice and 10% peanut butter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from ../AwareData/llama/llama-2-7b/llama-2-7b.Q5_K_M.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 17\n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q5_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 32\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 4096\n",
      "llm_load_print_meta: n_embd_v_gqa     = 4096\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 11008\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q5_K - Medium\n",
      "llm_load_print_meta: model params     = 6.74 B\n",
      "llm_load_print_meta: model size       = 4.45 GiB (5.68 BPW) \n",
      "llm_load_print_meta: general.name     = LLaMA v2\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.11 MiB\n",
      "llm_load_tensors: offloading 0 repeating layers to GPU\n",
      "llm_load_tensors: offloaded 0/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =  4560.87 MiB\n",
      "..................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 512\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =   256.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  256.00 MiB, K (f16):  128.00 MiB, V (f16):  128.00 MiB\n",
      "llama_new_context_with_model:        CPU input buffer size   =    10.01 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =    70.50 MiB\n",
      "llama_new_context_with_model: graph splits (measure): 1\n",
      "AVX = 0 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | MATMUL_INT8 = 0 | \n",
      "Model metadata: {'general.quantization_version': '2', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.model': 'llama', 'llama.attention.head_count_kv': '32', 'llama.context_length': '4096', 'llama.attention.head_count': '32', 'llama.rope.dimension_count': '128', 'general.file_type': '17', 'llama.feed_forward_length': '11008', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'general.architecture': 'llama', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'general.name': 'LLaMA v2'}\n",
      "Using fallback chat format: None\n"
     ]
    }
   ],
   "source": [
    "llm = Llama(model_path=\"../AwareData/llama/llama-2-7b/llama-2-7b.Q5_K_M.gguf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gather retrieval for LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use two sentences maximum and keep the answer concise. Question: 'What is chai made of?' Context:  Submission title: Chai latte Submission text: Newbie here. How is a hot Chai latte made? Thanks! Comment: 1. Steam 2% milk 2. Pump chai: 2/3/4/5 for short/tall/grande/venti  3. Fill cup halfway with hot water 4. Fill remaining half with steamed milk  (https://sbuxdates.com is a great site for checking recipes) Answer: \n"
     ]
    }
   ],
   "source": [
    "# Define prompt template\n",
    "ret_query = \"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use two sentences maximum and keep the answer concise. Question: '\" + query_string + \"' Context: \" + response_str + \" Answer: \"\n",
    "print(ret_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "_JamrqOqPRot"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    2196.75 ms\n",
      "llama_print_timings:      sample time =       6.50 ms /    76 runs   (    0.09 ms per token, 11692.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2196.63 ms /   180 tokens (   12.20 ms per token,    81.94 tokens per second)\n",
      "llama_print_timings:        eval time =    3314.73 ms /    75 runs   (   44.20 ms per token,    22.63 tokens per second)\n",
      "llama_print_timings:       total time =    5602.64 ms /   255 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': '1. Steam 2% milk 2. Pump chai: 2/3/4/5 for short/tall/grande/venti  3. Fill cup halfway with hot water 4. Fill remaining half with steamed milk  (https://sbuxdates.com is a great site for checking recipes)', 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}]\n"
     ]
    }
   ],
   "source": [
    "output = llm(\n",
    "      \"Q: \" + ret_query + \" A: \", # Prompt\n",
    "      max_tokens=None, # Generate up to 32 tokens, set to None to generate up to the end of the context window\n",
    "      stop=[\"Q:\", \"\\n\"], # Stop generating just before the model would generate a new question\n",
    "      echo=False # Echo the prompt back in the output\n",
    ") # Generate a completion, can also call create_completion\n",
    "print(output['choices'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Simple Query Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llamaRAGQuery(query_str, sub_data, full_data):\n",
    "    \n",
    "    #vector database\n",
    "    db = lancedb.connect(\"~/.lancedb\")\n",
    "    table = db.create_table('reddit_sb', sub_data, mode='overwrite')\n",
    "    \n",
    "    #query\n",
    "    query = model.encode(query_str,\n",
    "                       convert_to_numpy=True,\n",
    "                       normalize_embeddings=True).tolist()\n",
    "    #retrieval\n",
    "    response = table.search(query).limit(4).to_pandas()\n",
    "    \n",
    "    #build context (submission + top comment for each retrieved post)\n",
    "    response_str = \"\"\n",
    "    for i in range(len(response)):\n",
    "        sub_index = response.loc[i, 'index']\n",
    "        comment_indices = response.loc[i, 'comment_indices']\n",
    "        response_str = response_str + ' Submission title: ' +  full_data.loc[sub_index, 'reddit_title'] + ' Submission text: ' + full_data.loc[sub_index, 'reddit_text'] + ' Comment: ' + full_data.loc[comment_indices[0], 'reddit_text']\n",
    "    \n",
    "    \n",
    "    #feed query and context to llm\n",
    "    ret_query = \"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use two sentences maximum and keep the answer concise. Question: '\" + query_str + \"' Context: \" + response_str + \" Answer: \"\n",
    "    print(ret_query)\n",
    "    print(\"----------------------------------------------------\")\n",
    "    \n",
    "    output = llm(\n",
    "          \"Q: \" + ret_query[0:480] + \" A: \", # Prompt\n",
    "          max_tokens=None, # Generate up to 32 tokens, set to None to generate up to the end of the context window\n",
    "          stop=[\"Q:\", \"\\n\"], # Stop generating just before the model would generate a new question\n",
    "          echo=False # Echo the prompt back in the output\n",
    "    ) # Generate a completion, can also call create_completion\n",
    "    print(output['choices'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use two sentences maximum and keep the answer concise. Question: 'Do starbucks employees get paid time off?' Context:  Submission title: Sick hours Submission text: If I quit my job at Starbucks do they pay out our sick time? I am finally putting in my two week notice and I’m excited for something else. Comment: Only vacation Submission title: do vacation hours count toward benefit hours? Submission text:  Comment: Yes. Submission title: I know it varies by location/management…but does Starbucks typically honor scheduling restrictions? Submission text: I currently work a M-Th/T-F rotation and was thinking of applying to Starbucks for my Mondays, Fridays, Saturdays and Sundays off. If I can absolutely only work those days, will they typically stick to the hours you’re available, or do they try to throw you in days and times you’ve stated you can’t work? Comment: Once you work there theyll respect your avaiblity from my experience. However, you may have trouble getting hired in the first place if your availability is very restrivitive/ complicated such as alternating weeks Submission title: Returning for Degree & benefits Submission text: I am considering going back to work at Starbucks for a few years for an online ASU degree and for the benefits. Since I left in early 2020, I’ve heard some concerning things about the company. Is it likely to possibly be given not enough hours to even meet benefits, etc? As much as people complain about the company, they offer great benefits for it being an entry-level job. Comment: I came back for the sole benefit of college and I have been BEGGING FOR 13+ hours a week. Answer: \n",
      "----------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2196.75 ms\n",
      "llama_print_timings:      sample time =      25.20 ms /   393 runs   (    0.06 ms per token, 15594.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1293.35 ms /    61 tokens (   21.20 ms per token,    47.16 tokens per second)\n",
      "llama_print_timings:        eval time =   17471.35 ms /   392 runs   (   44.57 ms per token,    22.44 tokens per second)\n",
      "llama_print_timings:       total time =   19256.00 ms /   453 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': \" It's not clear what your job at Starbucks was in terms of hours per week or how often you worked. I worked as a barista in a Starbucks  A:  I worked at a Starbucks in Texas. I only worked there for 3 months but I did receive my sick days pay out at the end of  A:  I worked at Starbucks in North Carolina in 2015. I was a barista and I was paid a salary.  A:  Yes I worked at Starbucks for 5 months. I quit my job about 2 months ago. I do not remember if I was paid out my sick time or not but I did receive my last 2 pay checks  A:  I worked at Starbucks in Texas for a little under a year. I quit in August 2014. I was paid my sick time out when I quit  A:  I worked at a Starbucks in Georgia. I quit in January 2015. I did receive my sick time pay out at the end of my last month  A:  I worked at Starbucks from January 2015 - October 2015. I am not sure if I got paid out my sick time but I was paid out my vacation time at the end of 2015  A:  I worked at Starbuck from October 2015 - April 2016. I didn’t receive my sick time pay out at the end of my last paycheck in April 2016.  A:  I worked at Starbucks in Texas from September 2015 - December 2016. I was paid my sick time at the end of my last paycheck in December 2016  A:  I worked at\", 'index': 0, 'logprobs': None, 'finish_reason': 'length'}]\n"
     ]
    }
   ],
   "source": [
    "llamaRAGQuery(\"Do starbucks employees get paid time off?\", subs, data)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
